
# Writing CUDA python functions with intermediate variables

I have a 3 dimensional geometry consisting of n quadrilateral panels. That is, geometry.shape = (n,4,3). Each panel has a specific value stored in mu = np.array([mu1,...,mun]). For an arbitrary point in space, I would like to calculate the influence of all panels. Without going in to the physics of this problem, the influence of panel n is independent of the influence of panel n+1 and the calculation of the influence requires a set of rotations, multiplications etc.. for a large number of panels n. Hence, the problem is suitable for parallel programming. I am trying this with CUDA python. I already have the working code with @jit(nopython = True).
The problem I am encountering is best described by means of the following example.
def influence(point, panel):
   #do some stuff
   a = panel - point
   b = point - panel
   c = np.linalg.norm(a)/np.linalg.norm(b)
   return c

def solve_problem():
   center_points = get_centerpoints(geometry)
   n = geometry.shape[0]
   I_matrix = np.zeros((n,n))
   #I would like to use the GPU here
   for i in range(n):
      for j in range(n):
          I_matrix[i,j] = influence(center_points[i], geometry[j])
   return
   

The problem lies when trying to use @cuda.jit  to influence. I need to do intermediate operations on the array and derive a,b,cbefore computing the answer. However, I am not allowed to create variables or arrays in a CUDA jitted functions.
Are there workarounds or best practices?
I have tried to rewrite code in a way where I perform the calculation of the intermediate values before passing to GPU. However, this is a tremendous amount of work and feels superfluous.

        