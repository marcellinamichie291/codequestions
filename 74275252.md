
# Advice on sustainability and flaws in redis implementation

Hi I am using redis with redis-server (enabling the redis-server.service) and the python redis module on a 64-bit bullseye raspi, I am new to redis in general and would appreciate advice on my simple implementation.
I am using redis to store file names on creation as values to with sub-directories as keys, these are then read by a socket programme as a persistent ordered 'queue' where the head of list is taken and sent to the server, and then deleted if validation is sent back from the server.
Relevant code in the py script handling file creation:
redis_queue = Redis('127.0.0.1', 6379, decode_responses=True, db=1)

file_path = f'/home/json-files/{folder_name}/{message_name}-{timestamp}.json'
with open(file_path, 'w') as json_file:            
    json.dump(message, json_file)
redis_queue.rpush(message_name, file_path)

Relevant code in the socket.io client script:
redis_queue = Redis('127.0.0.1', 6379, decode_responses=True, db=1)

while redis_queue.llen(redis_key) > 0 and sio.connected:
    path = redis_queue.lindex(redis_key, 0)
    if send_data(path):
        redis_queue.lrem(redis_key, 0, path) 

The aim here is to prevent any data loss or data sent out of order of creation, particularly as a guard against network loss while the sensors providing the data to the files continue to operate. During initial testing it appears to be working reasonably well with a couple of instances of data duplication (of thousands) but it seems as though this may be more of an issue with the socket server.
I would appreciate any advice for being certain to guard against data loss/data out of order or something I may have overlooked in my use of redis.

        