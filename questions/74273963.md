
# Check whether Spark Dataframes are equal or not?

I am comparing two large dataframes about 100gb in pyspark, but before going into row level and column level validation, need to compare if there are indeeed some differences between the two dataframes.
I need a way I can generate a checksum or similar method for both dataframes which I can compare and say they are equal or not.
This is one way which I found which works with small dataset for both dataframes and compare if they are same, but unfortunately it will give me out of bounds memory for larger dataset since there is so much data to process.
df1=spark.read.format("csv").option("header","true").csv(file1)
print(hashlib.sha256(df1.toPandas().to_json().encode()).hexdigest())

Is there anyway, we can compare initially before going brute force for comparison?

        