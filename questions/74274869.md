
# Deep learning LSTM : How to improve my model to predict beyound validations ( future predictions)

I have created an LSTM predictor model that works verry good on the train (08years) and test (2years)sets, but i need now to predict beyond the dates in the entire dataset.
I woud like the predictions to go beyond the data in the dataset (after the 10years) (future predictions).
I ask some developers, He say to me just samll change and will done.
I try a lot of times but no result.
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
from rnn import RNN
import numpy as np
from torch import nn
import torch
from torch.autograd import variable


ss_X_dep = StandardScaler()
ss_y_dep = StandardScaler()
def rmse(y1, y2):
    return np.sqrt(mean_squared_error(y1, y2))

data = pd.read_csv('data/W042 RAIS/W042-Pz-4-Rais-SEAAl62-70.csv')

Inputs = data.drop('Year', axis=1).drop('Depth', axis=1)
Outputs = data['Depth']

Inputs = Inputs.to_numpy()
Outputs = Outputs.to_numpy().reshape(-1, 1)

# First 08 years of data

X_train_dep = Inputs[:62]
y_train_dep = Outputs[:62]

# Last 02 years of data
X_test_dep = Inputs[62:]

print("X_train_dep shape", X_train_dep.shape)
print("y_train_dep shape", y_train_dep.shape)
print("X_test_dep shape", X_test_dep.shape)

X = np.concatenate([X_train_dep, X_test_dep], axis=0)

# Standardization (Normalisation)
X = ss_X_dep.fit_transform(X)

# First 08 years of data
X_train_dep_std = X[:62]
y_train_dep_std = ss_y_dep.fit_transform(y_train_dep)

# All 10 years of data
X_test_dep_std  = X
X_train_dep_std = np.expand_dims(X_train_dep_std, axis=0)
y_train_dep_std = np.expand_dims(y_train_dep_std, axis=0)
X_test_dep_std = np.expand_dims(X_test_dep_std, axis=0)

# Transfer to Pytorch Variable
X_train_dep_std = variable(torch.from_numpy(X_train_dep_std).float()) 
y_train_dep_std = variable(torch.from_numpy(y_train_dep_std).float())
X_test_dep_std = variable(torch.from_numpy(X_test_dep_std).float())

# Les Hyper-param�tres du mod�le 

# Define rnn model
model = RNN(input_size=5, hidden_size=40, num_layers=1, class_size=1, dropout=0.5, rnn_type='lstm')

# Define optimization function
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)   # -4 optimize all rnn parameters
# Define loss function
loss_func = nn.MSELoss()

# Start training
for iter in range(2000+1):    # 20000 Iterations
    model.train()
    prediction = model(X_train_dep_std) 
    #X_train_dep_std.append(prediction)
    # prediction = model(X_train_dep_std)
    loss = loss_func(prediction, y_train_dep_std)
    optimizer.zero_grad()  # clear gradients for this training step
    loss.backward()        # back propagation, compute gradients
    optimizer.step()
    if iter % 100 == 0:
        print("iteration: %s, loss: %s" % (iter, loss.item()))

# Save model
save_filename = 'checkpoints/LSTM_DOUBLE_FC.pth'
torch.save(model, save_filename)
print('Saved as %s' % save_filename)

# Start evaluating model
model.eval()

y_pred_dep_ = model(X_test_dep_std).detach().numpy()
y_pred_dep = ss_y_dep.inverse_transform(y_pred_dep_[0, 0:])

print('The value of Root mean squared error (RMSE) of water table depth is :', rmse(Outputs[0:], y_pred_dep))
print('The value of mean squared error (MSE) of water table depth is :', mean_squared_error(Outputs[0:], y_pred_dep))
print('The value of R-squared (R2) of water table depth is :', r2_score(Outputs[0:], y_pred_dep))

f, ax1 = plt.subplots(1, 1, sharex=True, figsize=(15, 7
                                                 ))

ax1.plot(Outputs[0:], color="blue", linestyle="-", linewidth=2.5, label="Measurements")
ax1.plot(y_pred_dep, color="r", linestyle="--", linewidth=2.5, label="Proposed model")

plt.legend(loc='upper center')
plt.xticks(fontsize=10,fontweight='normal')
plt.yticks(fontsize=10,fontweight='normal')
plt.title('Predictions LSTM model W042-Pz-4-Rais-SEAAl 62-66', fontsize=15)
plt.xlabel('Mois d_apres le 2009-09', fontsize=15)
plt.ylabel('Variation de niveau statique NS (m)', fontsize=15)
plt.xlim(0, 85)
plt.savefig('./plots/lstm_doubl_aGood_Result.png', format='png')
plt.show()


        