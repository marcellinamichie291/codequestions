
# Find the closest value of each value in a column compared to another column in the same PySpark dataframe with exclusion criteria

I have a dataframe like this
Input

The ask was to "Find the closest "ratecode" corresponding to "offer1" (and save it as "offer1Ratecode") and "offer2" (saving as "offer2Ratecode"). " This question was asked here (Find the closest value of each value in a column compared to another column in the same PySpark dataframe) and answered by zygd (https://stackoverflow.com/users/2753501/zygd). The below piece of code accomplished this.

Output:

New Problem: Say , I have one more data frame like the one below:

My requirement now is that I shouldn't be selecting these rate codes in the offer1Ratecode and and offer2Ratecode columns , becuase these are agency rates and cannot be used as a offer to a subscriber.
New Output:

Simple ask is not to consider the agency rates in the function closest.
Any help will be greatly appreciated.
Sushant
Code snipper included in the qs

        