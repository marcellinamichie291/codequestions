
# Load large amount of data from the query result in memory in Python

What I want to do?
Get count of distinct rows of the table based on different possible column combinations. E.g. Say, a table has columns col1, col2, col3, col4, I would like to get counts of all different combinations of these 4 columns
SELECT count(*) FROM 
(SELECT DISTINCT <columns combinations>) FROM Table); 

columns combinations can be:

col1
col2
col3
col4
col1, col2
col1, col3
col1, col4
col1, col2, col3
and so on.

If I do this by running query for each possible combinations in  Python, it would be lot of queries that I need to run in Python which will be very slow.
What I tried and didn't work:
Load this data in memory and then get the row counts for each possible column combinations. The number of rows in a table are around 100M and number of possible cols is around 20 columns. Total size of data is around 5GB. The machine I am running these computations on is a 16GB RAM and 8 CPUs.
When I tried to load this data in pandas dataframe, then putting the data in dataframe doesn't finish in few hours. It looks like the bottleneck. Also, I don't know how slow the operation to get count from data frame would be.
Is there any better way to load this data in memory, where I can run count computations very fast? Or any other way to solve the problem?

        