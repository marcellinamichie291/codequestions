
# Is floating point math broken?

Consider the following code:

0.1 + 0.2 == 0.3  ->  false

0.1 + 0.2         ->  0.30000000000000004

Why do these inaccuracies happen?

        