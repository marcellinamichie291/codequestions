
# How to finetune a zero-shot text classification (NLI) model?

I have a long list of topics (say 80 topics) that I want to classify some documents under (a multi-label text classification), and I have very little labelled data (many topics do not have any labelled examples at all).
So I'm using a zero-shot text classification model (https://huggingface.co/cross-encoder/nli-deberta-v3-base), which works, but I would like to improve the performance of the model by finetuning its weights using the labelled data I have for some topics, while still retaining its zero-shot capabilities.
I've created a NLI dataset based on my small labelled dataset, in the format as follows:




Premise
Hypothesis
Label




this is the contents of the document for example it's about sports and tech
This example is Sports.
1


this is the contents of the document for example it's about sports and tech
This example is Technology.
1


this is the contents of the document for example it's about sports and tech
This example is Healthcare.
0




I did some simple data preprocessing for the document contents using the WordNinja library, which I used to split concatenated words like "hello,world" => "hello world". The library also removes punctuations, other than single-quote apostrophes (like in "it's"). The hypotheses are formed using the template of "This example is {topic}."
The labels 0 and 1 represent Contradiction and Entailment respectively - Entailment if the document is classified under the topic in my labelled dataset, otherwise Contradiction. There are 2396 Entailment labels in this NLI dataset I created, and 1931 Contradiction (ratio is fairly balanced).
I used the Trainer API to finetune the model for 10 epochs and during the training, the F1 score increased (when evaluating on a validation NLI dataset of a similar format). However, when I tried using the finetuned model for my initial task (zero-shot classification), the model kept predicting Entailment for nearly everything (precision was only 6%, recall was at 99%). I don't understand why, and what did I do wrong.
Any help will be appreciated!

        