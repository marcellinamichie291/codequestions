
# copy files from bitbucket repository to S3 bucket using python script

I am running a python script (through teamcity) which deploys AWS cloud formation templates. As a pre-requisite all the templates and script files in the bit bucket repository should be copied to S3 bucket before the deployment. How can python script copy files from different directories in bit bucket to S3.
I was using os.walk method to accomplish it, but it's not working fine.
Error: ValueError: Invalid extra_args key 'C', must be one of: ACL, CacheControl, ContentDisposition, ContentEncoding, ContentLanguage, ContentType, Expires, GrantFullControl, GrantRead, GrantReadACP, GrantWriteACP, Metadata, RequestPayer, ServerSideEncryption, StorageClass, SSECustomerAlgorithm, SSECustomerKey, SSECustomerKeyMD5, SSEKMSKeyId, Tagging, WebsiteRedirectLocation
pwd=os.getcwd()
print("Current Dir is: "+pwd)
print("Files in the Directory: ")
for subdir, dirs, files in os.walk(pwd):
    for file in files:
        print (file)
        try:
            object_name = file
            print("object name is"+object_name)
            response = client_bucket.upload_file(file, bucket_name, object_name)
        except:
            print("Error processing account " + account_id)
            for line in str(traceback.format_exc()).splitlines():
                print(line)


        