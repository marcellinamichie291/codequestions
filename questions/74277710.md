
# Spark Java: how to register a UDAF function using the new Aggregator<IN, BUF, OUT>

I'm using Java and can register an UDF function, and it works:
UDF1<Geometry, String> stGetUTMZone = new StGetUTMZone();
sparkSession.udf().register("ST_GetUTMZone", stGetUTMZone, DataTypes.StringType);

However, when I try registering an UDAF function, besides no compilation error is found, I get a runtime error due to datatype mismatch:
import org.locationtech.jts.geom.Geometry;
import org.apache.spark.sql.Encoders;

sparkSession.udf().register("ST_Safe_Union_Aggr",
        functions.udaf(new StSafeUnionAggregator(), Encoders.javaSerialization(Geometry.class)));

I tried also using Encoders.kryo() and Encoders.bean() with no success.
Is this the correct way for registering an UDAF function? I know Spark is written in Scala however I'd like to avoid rewriting our jobs in Scala.
I need to register an UDAF function in Java and tried using the functions.udaf() (Scala API) but it doesn't work as in Scala.
In Scala I would register the UDAF function using functions.udaf(myFunc) but in Java I cannot call it without passing 2 parameters.

        