
# Capturing and Storing Request Data Using Playwright for Python

I'm working with playwright in python (after giving up on a proxymob approach), and I'm trying to capture all headers from a given request/response using the below code:
import asyncio
from time import sleep
from urllib import request
from playwright.async_api import async_playwright
from playwright.sync_api import sync_playwright

async def main():
async with async_playwright() as p:
    for browser_type in [p.chromium, p.firefox, p.webkit]:
        browser = await browser_type.launch(headless=False)
        page = await browser.new_page()
        page.on("request", lambda request: print(str(request.method), str(request.url), str(request.all_headers())))
        page.on("response", lambda response: print(str(response.all_headers())))
        
        # I navigate to some page
        await asyncio.sleep(15)

asyncio.run(main())

The output I get is:
<bound method Request.all_headers of <Request url='...' method='GET'>
<bound method Response.all_headers of <Response url='...'>

As you can see, the output I'm getting isn't useful. Now if I use the "sync" approach I'm able to see the actual headers in the output. However, I'm using the async approach as I'd like to capture the data as I am browsing rather than having to hardcode the navigation (minds of well use devtools at that point).
So here are my questions:

How would I expose the headers in the output using the async approach above?
How would I store said output in a dictionary?

Lamda expects a function and I've tried creating a custom function that adds the output to a dictionary, but nothing winds up getting stored (whether async or sync).
Feedback is much appreciated!

        