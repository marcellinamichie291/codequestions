
# Training a decision tree on two different feature sets python scikit

I am trying to train a decision tree using scikit. One of my feature sets looks something like this:
X = [[0, 0], [1, 1]]
Y = ['a','b'] #class labels 
The other feature set looks like this: 
Z = [[1,2,0.5],[2,1,0.5],[0.5,2,2]
Y = ['a','b','a'] #class labels 

I know that if I have only one feature set, I can do this:
clf = tree.DecisionTreeClassifier()
clf = clf.fit(X, Y)

To consider the Z feature set too, should I do just another:
clf = clf.fit(Z, Y)

Or will this just overwrite my fit for X?
The number of samples in X and Z are different, which is why I can't just zip them together.

        