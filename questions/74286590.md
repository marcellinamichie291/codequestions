
# concatenate file with same prefix filename using python in databricks

I have many csv files in a directory, each of them have the same name with a different number at the end. For example:
20210430_FH_Newsletter_1.csv
20210430_FH_Newsletter_2.csv
20210628_my Neighbourhood_1.csv
20210628_my Neighbourhood_2.csv
20220119_xyz.csv
20220220_abc.csv
I want to check for first 8 characters and if file names are matching then I want to concatenate files like below 20210430_FH_Newsletter.csv (20210430_FH_Newsletter_1.csv and 20210430_FH_Newsletter_2.csv will be merged). Similarly, for 20210628_my Neighbourhood.csv (20210628_my Neighbourhood_1.csv and 20210628_my Neighbourhood_2.csv will be merged).
I am working in databricks and the path is defined.
I am able to read the files from the path and identify the files having first 8 charcaters as same:
paths = "abfss://xyz.dfs.core.windows.net/demo/input/demo_1/ABC_folder/Canada"
 for i in range (0,(len(paths)-1)):
        zeroes=[]
        if paths[i].split("Canada/")[1].split("_")[0]==paths[i+1].split("Canada/[1].split("_")[0]:
           zeroes.append(paths[i])
           zeroes.append(paths[i+1])
           print(zeroes)

which gives me the list of files with the first character same as:
['abfss://xyz.dfs.core.windows.net/demo/input/demo_1/ABC_folder/Canada/20210430_FH_Newsletter_1.csv', 'abfss://xyz.dfs.core.windows.net/demo/input/demo_1/ABC_folder/Canada/20210430_FH_Newsletter_2.csv']
 ['abfss://xyz.dfs.core.windows.net/demo/input/demo_1/ABC_folder/Canada/20210628_my Neighbourhood_1.csv', 'abfss://xyz.dfs.core.windows.net/demo/input/demo_1/ABC_folder/Canada/20210628_my Neighbourhood_2.csv']

After that I tried to append the list into an empty dataframe but it is only appending the last list:
df=[]
for j in zeroes:
   dbutils.fs.cp(j,'dbfs:/tempx.csv')
   file_read_1 = pd.read_csv('/dbfs/tempx.csv',encoding='utf-8')
   df.append(file_read_1)
   frame = pd.concat(df, axis=0, ignore_index=True)

Can you guys please suggest what i am doing wrong- here.

        