
# Why can't I set dtype object data as strings

I scrapped review data from the google play store page of an app using the google-play-scraper app. That gave me a list of all the reviews, scores, time etc... I converted the list to a dataframe and copied the review content and scores into another dataframe.
Every time I attempt to do something to the strng data of the reviews I just get the
TypeError: expected string or bytes-like object


error.
I've tried using:
reviews['cont_str']= reviews['cont_str'].astype(str) 

but the column is still only listed as an object and when I attempt to tokenize or perform any string related function, it fails with the typerror error.
I would like to change each row in the content column from an object to a string so that I can do some sentiment analysis on them. I have just hit a wall as to where I've gone wrong.
Here's an example of what happens when I try tokenizing the text in the dataframe column:
regexp = RegexpTokenizer('\w+')

reviews['cont_str']=reviews['cont_str'].apply(regexp.tokenize)

And here's the error in full:
TypeError                                 Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_28840/125171906.py in <module>
      1 regexp = RegexpTokenizer('\w+')
      2 
----> 3 reviews['cont_str']=reviews['cont_str'].apply(regexp.tokenize)
      4 reviews.head(3)

i:\anaconda3\lib\site-packages\pandas\core\series.py in apply(self, func, convert_dtype, args, **kwargs)
   4431         dtype: float64
   4432         """
-> 4433         return SeriesApply(self, func, convert_dtype, args, kwargs).apply()
   4434 
   4435     def _reduce(

i:\anaconda3\lib\site-packages\pandas\core\apply.py in apply(self)
   1086             return self.apply_str()
   1087 
-> 1088         return self.apply_standard()
   1089 
   1090     def agg(self):

i:\anaconda3\lib\site-packages\pandas\core\apply.py in apply_standard(self)
   1141                 # List[Union[Callable[..., Any], str]]]]]"; expected
   1142                 # "Callable[[Any], Any]"
-> 1143                 mapped = lib.map_infer(
   1144                     values,
   1145                     f,  # type: ignore[arg-type]

i:\anaconda3\lib\site-packages\pandas\_libs\lib.pyx in pandas._libs.lib.map_infer()

i:\anaconda3\lib\site-packages\nltk\tokenize\regexp.py in tokenize(self, text)
    131         # If our regexp matches tokens, use re.findall:
    132         else:
--> 133             return self._regexp.findall(text)
    134 
    135     def span_tokenize(self, text):

TypeError: expected string or bytes-like object


        