
# Grep multiple inputs from huge file, but only the first occurance each

I am trying to build a "unique" zipcode list based on the data from geojson.
The goal is to grep one whole line per zip code. There are multiple entries per zipcode possible, all i care is about grabbing one per Zip.
ive prepared a "unique" zip code file to pass as grep to run as a "filter" against the list.
However, this still returns multiple results per zip code.
When limiting the results with -m 1 then i only get the very first match.
How can i filter one entry per line from the "big file"?
The input (example)
9417 TG
9423 TA
9431 HK
9883 TB
9965 TN

The command:
grep -f infile.txt bigfile.txt
the output:
9417 TG Spier   Drenthe                                 NLD Netherlands 52.8178 6.4592  ;
9423 TA Hoogersmilde    Drenthe                                 NLD Netherlands 52.9098 6.3685  ;
9417 TG Spier   Drenthe                                 NLD Netherlands 52.8178 6.4658  ;
9423 TA Hoogersmilde    Drenthe                                 NLD Netherlands 52.9066 6.3802  ;
9431 HK Westerbork  Drenthe                                 NLD Netherlands 52.8613 6.6029  ;
9431 HK Oosterwolde Friesland                                   NLD Netherlands 52.9851 6.2986  ;
9883 TB Zuurdijk    Groningen                                   NLD Netherlands 53.3147 6.3558  ;
9965 TN Zuurdijk    Groningen                                   NLD Netherlands 53.3506 6.3691  ;
9965 TN Leens   Groningen                                   NLD Netherlands 53.3523 6.37    ;
9883 TB Oldehove    Groningen                                   NLD Netherlands 53.3108 6.3632  ;

As you can see, there are two entries for 9423 TA and 9965 TN
How can I crunch that down to one entry per list?
Thank you kindly for your help!

        