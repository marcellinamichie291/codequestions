
# VAE on a 3D point cloud of shape (n,3)

I have a 3D point cloud of shape (200,162,3) - Example shape. Assume this can of shape (n,m,3).
I am trying to build a Variational Autoencoder to reduce this to a latent space for optimization. Does it make sense to use VAE for a point cloud?
I have the following questions as I am struggling to implement the loss function for this.

My current architecture has me reducing the data from (n,m,3) ----> (7) -------> (n,m,3)
I am trying to implement a chamfer distance as a loss function to work as a reconstruction error metric.
I am passing in the input image and the decoder output to the loss function to compute chamfer distance. Am I doing this right? Is this the right thinking?
I am having some eager execution vs graph execution error when I pass in my tensors to the loss function.
Are there any implementations for a point cloud autoencoder?


        