
# Keeping mongo _ids consistent in an AWS Glue Job sync to mongodb

I am writing a glue job that syncs from AWS S3 parquet format to mongodb.
S3/Parquet (source) ---------- (aws glue job) ---------> Mongo (sink)

In AWS glue, to achieve this we set the source to parquet and the sink to be documentdb. Options for source and sink are documented here.
To prevent future runs of the job from creating new/duplicate data, we need to make sure replaceDocument is set to true, and that we are generating a unique _id for every document. Here is the relevant documentation on replaceDocument.

"replaceDocument": (Optional) If true, replaces the whole document
when saving datasets that contain an _id field. If false, only fields
in the document that match the fields in the dataset are updated. The
default is true.

Now, all that said, it seems I need to generate an _id for every document in the glue job. I could just use one of the unique fields from the parquet collection and create a string _id. But it seems a little hokey, because I know there are some mongo operations that rely on mongo creating a chronologically increasing ObjectId(). I can spoof a ObjectId() in the glue job, but once again not sure what to use for the parts of that ObjectId(). Any straightforwards solutions I am overlooking?

        