
# R curl package multi-threading

I am trying to use R's curl package to retrieve results from a web service. Suppose I have to hit the service with 16 different versions of parameters and each hit takes 10 seconds. If I simultaneously spawn 16 different requests, it should theoretically take 10 seconds for the whole thing rather than 160 seconds.
Is the simplest way to do this via the parallel package's mclapply? Or, is there a more elegant solution with something like curl_fetch_multi? Ideally, I could parallelize on the host service's server rather than my own as it should theoretically be setup to handle many different requests.

        