
# How to create a pipeline for database, image transformation and ML?

I have several csv files that are exported to a Postgres database using a R script. Then, using information from these tables (including image paths and dimensions), images are loaded, rotated and cropped with a Python script. Different versions of the images are created and are then used as gold standard to train a Machine Learning algorithm (Tensorflow). For now, all steps are done with custom scripts. But I would need a better way, and the possibility to integrate new data (new entries on the csv files) in the pipeline without re-doing the transformations on all images. What could be possible? What tools exist?

        