
# Confusion matrix inconsistent with recall

I am checking the metrics in an AutoML model trained in Vertex AI. It shows:
enter image description here
The recall (or true positive rate) is 72%, then the false negative rate is around 28% (must exits data points classified as 0). But the confusion matrix is inconsistent with this enter image description here (according to that no one obeservation is predicted as 0 by the model). Someone have a clue for what is happening?

        