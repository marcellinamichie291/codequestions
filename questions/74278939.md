
# Best method of calling multiple async API calls concurrently?

So, I have a process where I'm trying to analyze a high number of registered users (currently about 45,000). Currently, I analyze each character one by one, which is extremely inefficient and now too costly in terms of time. I am attempting to develop a method of analyzing a number of characters concurrently to shrink the time it takes to analyze the entire load. However, I have a few constraints: 1) the library I rely on to interface with the API is asynchronous, and 2) the API I'm dealing with rate limits at a rate of 250/10s (25/s). I want to ideally split the total users into groups of 10, and process 10 users at a time, since most of the time any user processing shouldn't use more than 2 calls per second. However, I have a feeling this is also not ideal, simply because even though I split the load, I wouldn't be able to process the next set of 10 until the slowest of the set of 10 is finished processing. Hence, I am looking for tips as to what is an efficent way to do this, both hypothetically and using an actual library.
I've tried a few different methods so far, using the new Task Groups from asyncio's 3.11 update, some general things with asyncio.gather, and some stuff with ThreadPoolExecutors. However, nothing has worked just yet. I'm not necessarily looking for the code to get this done, but is there a library I should be looking into for this, or a specific method that would be best?
Essentially, here is a very broad overview of what I'm looking to do.
async def processCharacter():
    await API_Call()
    await updateUser();

async def main(): 
    characters = await getAllCharacters()
    groups = await splitAllCharactersIntoGroups(characters)
    await concurrentlyProcessCharacters(groups)


        