
# Fit Vectorization-Output for RNN-Input

I have a Keras model that text Text as an Input, vectorizes it via the TextVectorization-Layer via multi_hot encoding. The problem is that this layer outputs a Tensor with the shape (None,batch_size). The next layer, SimpleRNN, requires a Tensor with 3 Dimensions. How can I convert this output without using an Embedding-Layer?
I already tried different Layers to work with my Input, reshaping the np-arrays. Here is my current code:
X_Train = np.asarray(X_Train)
X_Test = np.asarray(X_Test)
Y_Train = np.asarray(Y_Train)
Y_Test = np.asarray(Y_Test)

vectorizer = TextVectorization(standardize=None,split=None,output_mode="multi_hot")
vectorizer.adapt(X_Train)

model = Sequential()
model.add(Input(shape=(1),dtype="string"))
model.add(vectorizer)
print(vectorizer.output_shape)
#model.add(Embedding(datasetSize,2))
model.add(layers.SimpleRNN(nodes,activation=activationFunc))
model.add(Dense(1,activation=None,use_bias=False))

model.compile(optimizer=optimizerFunc,loss=lossFunc)
model.summary()

It works using the Embedding-Layer, but I need it to work without at.
My data is basically a csv-File with the format




Word
Weight




word1
1


word2
2




The goal is to let the network predict the weight of any given word based on this data.
Any idea how to make it work with this?

        