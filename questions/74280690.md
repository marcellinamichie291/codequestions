
# How to tune a custom classifier in sklearn with additional required parameters in fit and predict methods?

For the purposes of this question, I have created a dummy dataset below:
import numpy as np
import pandas as pd

cities = ['Berlin', 'Frankfurt', 'Hamburg', 
          'Nuremberg', 'Munich', 'Stuttgart',
          'Hanover', 'Saarbruecken', 'Cologne',
          'Constance', 'Freiburg', 'Karlsruhe'
         ]

n= len(cities)

data = pd.DataFrame({
    'City':cities,
    'Temperature': np.random.normal(24, 3, n),
    'Humidity': np.random.normal(78, 2.5, n),
    'Wind': np.random.normal(15, 4, n),
    'Target': np.random.randint(2, size=n)
})

I have a (simplified) custom classifier below which maps the text feature to a continuous value before combining it with the remaining features for classification:
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier

class CustomClassifier(ClassifierMixin, BaseEstimator):
    def __init__(self, n_estimators=100):
        
        self.n_estimators=100
        
        self.NLP = Pipeline(
            [
                ('preprocessor', TfidfVectorizer()),
                ('regressor', LogisticRegression())
            ]
        )
        
        self.Classifier = GradientBoostingClassifier(n_estimators=self.n_estimators)

    def fit(self, X, y, text_data, **kwargs):
        self.NLP.fit(text_data, y)
        text_feature = self.NLP.predict_proba(text_data)
        
        new_X = np.concatenate(
            (text_feature[:,1, np.newaxis], X), 
            axis=1
        )
        
        self.Classifier.fit(new_X, y)
        
        return self

    def predict(self, X, text_data):
        text_feature = self.NLP.predict_proba(text_data)
        
        new_X = np.concatenate(
            (text_feature[:,1, np.newaxis],X), 
            axis=1
        )
        
        y_pred = self.Classifier.predict(new_X)
        return y_pred

I can run fit and predict without issue, but if I try to tune the pipeline using cross validation as follows:
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MaxAbsScaler
from sklearn.model_selection import RandomizedSearchCV

custom_model = CustomClassifier()

pipe = Pipeline([
    ('scaling', MaxAbsScaler()),
    ('classifier', custom_model)
])

params = {'classifier__n_estimators':[100,200]}

tuner = RandomizedSearchCV(
    pipe, 
    param_distributions=params, 
    cv=3, 
    n_iter=2
)

tuner.fit(X=data.drop(['City', 'Target'], axis=1), y=data.loc[:,'Target'], classifier__text_data=data.loc[:,'City'])

I receive the following error:
predict() missing 1 required positional argument: 'text_data'

Which also prevents me from using something like cross_val_score.
Any ideas on how I can approach tuning my custom pipeline?
This might be a limitation of the RandomizedSearchCV class (which does not accept additional parameters in predict), so I tried to write a custom class with a custom predict method:
class RandomizedSearchCVPlus(RandomizedSearchCV):
    def predict(self, X, **predict_params):
        
        return self.best_estimator_.predict(X, **predict_params)

But this did not solve the issue.

        