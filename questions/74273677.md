
# How do i save one subscription pub/sub message to three different big query tables in apache beam in python?

I have created three process and want to save data but this is not working for me.
Below is my custom pardo:

subscription = "pub/sub/writeToBigquery"
dataset_table1="A"
dataset_table2="B"
dataset_table3="c"
Schema1="et:timestamp,name:string,Day:integer"
schema2="et:timestamp,Place:string,Month:integer"
schema3="et:timestamp,Location:string,Year:integer"

    class CustomParsing(beam.DoFn):

        def process1(self, element, timestamp=beam.DoFn.TimestampParam):
            parsed = dict()
            parsed = json.loads(element.decode("utf-8"))
            parsed["et"] = parsed.et,
            parsed["name"] = parsed.name
            parsed["Day"] = parsed.day
            yield parsed

       def process2(self, element, timestamp=beam.DoFn.TimestampParam):
            parsed = dict()
            parsed = json.loads(element.decode("utf-8"))
            parsed["et"] = parsed.et,
            parsed["name"] = parsed.place
            parsed["Day"] = parsed.month
            yield parsed

      def process3(self, element, timestamp=beam.DoFn.TimestampParam):
            parsed = dict()
            parsed = json.loads(element.decode("utf-8"))
            parsed["et"] = parsed.et,
            parsed["name"] = parsed.location
            parsed["Day"] = parsed.year
            yield parsed

How to write this in big query??

        