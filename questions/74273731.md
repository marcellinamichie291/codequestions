
# How to replace the criterion which is used to find best split variable in extra trees?

My goal is to revise the split criterion of the regression tree algorithm so that the structure of the regression tree is independent of the output values of the learning sample.
It is obvious that the CART used by Random Forest does not satisfy, but Extra Trees may satisfy. In Pierre Geurts et al.(2006) 's opinion, in the extreme case, extremely randomized trees build totally randomized trees whose structures are independent of the output values of the learning sample. However, the score they used is dependent on the output. 
In my limited experience with Extra Tree in Python and R, the score to find the best split variable is also reliable on the output. As a result, I can't use extra trees directly.
I have tried to revise the criterion in source code in R and Python, but it is difficult for me because it is written in C which I'm not familiar with.
Are there any other existing tree algorithms that satisfy independence? Thanks in advance.

        